ggplot(data = regions) +
kaplot::theme_solarized_mk(base_size = 16, light = FALSE) +
# theme_classic(base_size = 14) +
# geom_sf(data = clips[[1]], fill = demPal[1], alpha = 0.9, color = NA) +
# geom_sf(data =  clips[[2]], fill = demPal[2], alpha = 0.9, color = NA) +
## for orthogonal
# geom_sf(data = B1, fill = 'dodgerblue4', alpha = 0.9, color = NA) +
# geom_sf(data = B2, fill = 'gold', alpha = 0.9, color = NA) +
## for 50 only
# geom_sf(data = n50_shape, fill = 'dodgerblue4', alpha = 0.9, color = NA) +
# geom_sf(data = n36_shape, fill = 'gold', alpha = 0.9, color = NA) +
# geom_sf(data = clips[[3]], fill = demPal[3], alpha = 0.9, color = NA) +
# geom_sf(data = clips[[4]], fill = demPal[4], alpha = 0.9, color = NA ) +
# geom_sf(data = clips[[5]], fill = demPal[5], alpha = 0.9, color = NA) +
# geom_sf(data = clips[[6]], fill = demPal[6], alpha = 0.9,color = NA) +
## for mgmt only
geom_sf(data = clips[[3]], fill = regPal[3], alpha = 0.9, color = NA) +
geom_sf(data = clips[[4]], fill = regPal[4], alpha = 0.9, color = NA ) +
geom_sf(data = clips[[5]], fill = regPal[5], alpha = 0.9, color = NA) +
geom_sf(data = clips[[6]], fill = regPal[6], alpha = 0.9,color = NA) +
geom_sf(data =   st_union(x=clips[[2]],y=clips[[3]])  ,
fill = NA, lwd = 1.1,color = regPal[1], linetype = 'dashed') +
##r2
geom_sf(data =   st_union(x=clips[[4]],y=clips[[5]])  ,
fill = NA, lwd = 1.1,  color = regPal[2], linetype = 'dashed') +
## show demography
##R3
# geom_sf(data =   st_union(x=clips[[2]],y=clips[[3]])  ,
#         fill = NA, lwd = 1.1,color = 'red', linetype = 'dashed') +
# ##r2
# geom_sf(data =   st_union(x=clips[[4]],y=clips[[5]])  ,
#         fill = NA, lwd = 1.1,  color = 'red', linetype = 'dashed') +
## EEZ
geom_sf(lwd = 1, col = 'grey88', fill = NA) +
# geom_label(data = data.frame(), aes(
#   # x = c(238, 233, 232, 233, 225, 220, 200),
#   # y = c(33, 40, 49, 51, 52, 57, 53)),
#   x = c(238, 233, 232, 225, 220, 200),
#   y = c(33, 40, 49, 52, 57, 53)),
#   label = c("C1", "C2", "B1","B2","A2", "A1") ,
#
#   # label = c("C1", "C2", "B1","B2", "B3", "A2", "A1") ,
#   # size = 5,
#   fill = demPal[c(6:1)],
#   color = c("grey88", rep('black',3), rep('black',2))) +
coord_sf(xlim = c(165, 245), ylim = c(30, 65)) +
labs(x ="",y="")
ggplot(data = regions) +
kaplot::theme_solarized_mk(base_size = 16, light = FALSE) +
# theme_classic(base_size = 14) +
# geom_sf(data = clips[[1]], fill = demPal[1], alpha = 0.9, color = NA) +
# geom_sf(data =  clips[[2]], fill = demPal[2], alpha = 0.9, color = NA) +
## for orthogonal
# geom_sf(data = B1, fill = 'dodgerblue4', alpha = 0.9, color = NA) +
# geom_sf(data = B2, fill = 'gold', alpha = 0.9, color = NA) +
## for 50 only
# geom_sf(data = n50_shape, fill = 'dodgerblue4', alpha = 0.9, color = NA) +
# geom_sf(data = n36_shape, fill = 'gold', alpha = 0.9, color = NA) +
# geom_sf(data = clips[[3]], fill = demPal[3], alpha = 0.9, color = NA) +
# geom_sf(data = clips[[4]], fill = demPal[4], alpha = 0.9, color = NA ) +
# geom_sf(data = clips[[5]], fill = demPal[5], alpha = 0.9, color = NA) +
# geom_sf(data = clips[[6]], fill = demPal[6], alpha = 0.9,color = NA) +
## show demography
##R3
# geom_sf(data =   st_union(x=clips[[2]],y=clips[[3]])  ,
#         fill = NA, lwd = 1.1,color = 'red', linetype = 'dashed') +
# ##r2
# geom_sf(data =   st_union(x=clips[[4]],y=clips[[5]])  ,
#         fill = NA, lwd = 1.1,  color = 'red', linetype = 'dashed') +
## EEZ
geom_sf(lwd = 1, col = 'grey88', fill = NA) +
# geom_label(data = data.frame(), aes(
#   # x = c(238, 233, 232, 233, 225, 220, 200),
#   # y = c(33, 40, 49, 51, 52, 57, 53)),
#   x = c(238, 233, 232, 225, 220, 200),
#   y = c(33, 40, 49, 52, 57, 53)),
#   label = c("C1", "C2", "B1","B2","A2", "A1") ,
#
#   # label = c("C1", "C2", "B1","B2", "B3", "A2", "A1") ,
#   # size = 5,
#   fill = demPal[c(6:1)],
#   color = c("grey88", rep('black',3), rep('black',2))) +
coord_sf(xlim = c(165, 245), ylim = c(30, 65)) +
labs(x ="",y="")
ggsave(last_plot(),
file = "C:/Users/mkapur/Dropbox/mkapur.github.io/static/slides/kapur_genex/demog_dark3.png",
width = 10, height = 8)
library(tidyverse)
library(FishLife)
library(spasm)
#' length_to_age
#'
#' @param length_samples
#' @param cv
#' @param k
#' @param linf
#' @param t0
#' @param max_age
#'
#' @return a data frame of estimated numbers at age
#' @export
#'
length_to_age <-
function(length_samples,
cv,
k,
linf,
t0,
max_age,
min_age = 0,
time_step = 1,
aging_method = "vbk") {
if (aging_method == "vbk"){
age_comp <- length_samples %>%
mutate(next_bin = lead(length_bin)) %>%
mutate(mid_bin = map2_dbl(length_bin, next_bin, ~mean(c(.x,.y), na.rm = T))) %>%
mutate(expected_age = (log(1 - pmin(0.99*linf,mid_bin) / linf) / -k) - t0) %>%
mutate(rounded_age = plyr::round_any(expected_age, time_step, f = floor)) %>%
group_by(rounded_age) %>%
summarise(numbers = sum(numbers)) %>%
rename(age = rounded_age)
blank_ages <- data_frame(age = seq(min_age, max_age, by = time_step), blanks = 0)
age_comp <- age_comp %>%
right_join(blank_ages, by = "age") %>%
ungroup() %>%
mutate(numbers = ifelse(is.na(numbers), 0 , numbers)) %>%
select(-blanks)
} else if (aging_method == "key") {
warning("aging by key DOES NOT work correctly right now")
mean_length_at_age <-
linf * (1 - exp(-k * (seq(
min_age, max_age, by = time_step
) - t0)))
length_at_age_vars <- data_frame(
age =  seq(min_age, max_age, by = time_step),
mean_length_at_age = mean_length_at_age,
sigma_at_age = cv * mean_length_at_age
) #calculate standard deviation of length at age for each age bin
# now calculate the probability of being in each length bin at each age
p_length_at_age <-
expand.grid(
age =  seq(min_age, max_age, by = time_step),
length_bin = 0:(10 * linf)
) %>%
as_data_frame() %>%
left_join(length_at_age_vars, by = 'age') %>%
arrange(age, length_bin)
p_length_at_age <- p_length_at_age %>%
group_by(age) %>%
mutate(next_length_bin = lead(length_bin, 1)) %>%
mutate(p_bin = ifelse(
is.na(next_length_bin) == F,
pnorm(next_length_bin, mean_length_at_age, sigma_at_age),
1
) -
pnorm(length_bin, mean_length_at_age, sigma_at_age))
#rescale probabilities by the probability of being in an age bin at a given length``
p_length_at_age <- p_length_at_age %>%
group_by(length_bin) %>%
mutate(p_age_at_length = p_bin / sum(p_bin, na.rm = T))
p_length_at_age$p_age_at_length[is.na(p_length_at_age$p_age_at_length)] <- 0
# p_length_at_age %>%
#   ggplot(aes(age, p_age_at_length)) +
#   geom_col() +
#   facet_wrap(~length_bin)
#
# Bin lengths into age bins, and then join the probability of being in each age as a function
# of length size
lengths_to_ages <- length_samples %>%
left_join(p_length_at_age %>% select(length_bin, age, p_age_at_length),
by = 'length_bin')
# lengths_to_ages <- data_frame(lengths = lengths) %>%
#   mutate(length_bin = floor(lengths)) %>%
#   group_by(length_bin) %>%
#   summarise(samples = length(lengths)) %>%
#   left_join(p_length_at_age %>% select(length_bin, age, p_age_at_length),
#             by = 'length_bin')
# Assign lengths to ages in proportion to the probability of age at length
age_comp <- lengths_to_ages %>%
ungroup() %>%
mutate(numbers = numbers * p_age_at_length) %>%
group_by(age) %>%
summarise(numbers = sum(numbers, na.rm = T)) %>%
mutate(age = age)
}
return(age_comp)
}
mapply(list.files(getwd(),"/_examples/spasm-master/R"))
mapply(list.files("./_examples/spasm-master/R"), source)
mapply(source,list.files("./_examples/spasm-master/R"), )
sapply(list.files("./_examples/spasm-master/R"), source)
sapply(list.files("./_examples/spasm-master/R", full.names = TRUE), source)
fish <-
create_fish(
scientific_name = "Lutjanus campechanus",
query_fishlife = T,
mat_mode = "length",
time_step = 1,
sigma_r = 0.1,
price = 5,
price_cv = 0,
price_ac = 0.25,
steepness = 0.6,
r0 = 1000,
rec_ac = 0.25
)
cv = 0.2
k = 0.3
linf = 150
t0 = -2
max_age = 95
min_age = 1
min_age = 0
age_comp <- length_samples %>%
mutate(next_bin = lead(length_bin)) %>%
mutate(mid_bin = map2_dbl(length_bin, next_bin, ~mean(c(.x,.y), na.rm = T))) %>%
mutate(expected_age = (log(1 - pmin(0.99*linf,mid_bin) / linf) / -k) - t0) %>%
mutate(rounded_age = plyr::round_any(expected_age, time_step, f = floor)) %>%
group_by(rounded_age) %>%
summarise(numbers = sum(numbers)) %>%
rename(age = rounded_age)
mean_length_at_age <-
linf * (1 - exp(-k * (seq(
min_age, max_age, by = time_step
) - t0)))
length_at_age_vars <- data_frame(
age = seq(min_age, max_age, by = time_step),
mean_length_at_age = mean_length_at_age,
sigma_at_age = cv * mean_length_at_age
) #calculate standard deviation of length at age for each age bin
# now calculate the probability of being in each length bin at each age
p_length_at_age <-
expand.grid(
age = seq(min_age, max_age, by = time_step),
length_bin = 0:(linf_buffer * linf)
) %>%
as_data_frame() %>%
left_join(length_at_age_vars, by = 'age') %>%
arrange(age, length_bin)
p_length_at_age <- p_length_at_age %>%
group_by(age) %>%
mutate(next_length_bin = lead(length_bin, 1)) %>%
mutate(p_bin = ifelse(
is.na(next_length_bin) == F,
pnorm(next_length_bin, mean_length_at_age, sigma_at_age),1) - pnorm(length_bin, mean_length_at_age, sigma_at_age))
p_length_at_age
require(ggplot2)
ggplot(p_length_at_age, aes(x = age, y = length_bin, fill = p_bin)) +geom_tile()
tail(p_length_at_age)
linf
linf = 70
mean_length_at_age <-
linf * (1 - exp(-k * (seq(
min_age, max_age, by = time_step
) - t0)))
length_at_age_vars <- data_frame(
age = seq(min_age, max_age, by = time_step),
mean_length_at_age = mean_length_at_age,
sigma_at_age = cv * mean_length_at_age
) #calculate standard deviation of length at age for each age bin
# now calculate the probability of being in each length bin at each age
p_length_at_age <-
expand.grid(
age = seq(min_age, max_age, by = time_step),
length_bin = 0:(linf_buffer * linf)
) %>%
as_data_frame() %>%
left_join(length_at_age_vars, by = 'age') %>%
arrange(age, length_bin)
p_length_at_age <- p_length_at_age %>%
group_by(age) %>%
mutate(next_length_bin = lead(length_bin, 1)) %>%
mutate(p_bin = ifelse(
is.na(next_length_bin) == F,
pnorm(next_length_bin, mean_length_at_age, sigma_at_age),1) - pnorm(length_bin, mean_length_at_age, sigma_at_age))
ggplot(p_length_at_age, aes(x = age, y = length_bin, fill = p_bin)) +geom_tile()
p_length_at_age
ggplot(subset(p_length_at_age, p_bin < 1), aes(x = age, y = length_bin, fill = p_bin)) +geom_tile()
subset(p_length_at_age, p_bin < 1)
ggplot(subset(p_length_at_age, p_bin < 1.00), aes(x = age, y = length_bin, fill = p_bin)) +geom_tile()
p_length_at_age
subset(p_length_at_age, p_bin < 1.00)
class(p_length_at_age$p_bin)
hist(p_length_at_age$p_bin)
p_length_at_age %>% filter(p_bin <1)
p_length_at_age %>% filter(p_bin <1.00)
p_length_at_age %>% filter(!is.na(next_length_bin))
ggplot(p_length_at_age %>% filter(!is.na(next_length_bin)), aes(x = age, y = length_bin, fill = p_bin)) +geom_tile()
ggplot(p_length_at_age %>% filter(!is.na(next_length_bin)), aes(x = age, y = length_bin, fill = p_bin*100)) +geom_tile()
max_age = 30
mean_length_at_age <-
linf * (1 - exp(-k * (seq(
min_age, max_age, by = time_step
) - t0)))
length_at_age_vars <- data_frame(
age = seq(min_age, max_age, by = time_step),
mean_length_at_age = mean_length_at_age,
sigma_at_age = cv * mean_length_at_age
) #calculate standard deviation of length at age for each age bin
# now calculate the probability of being in each length bin at each age
p_length_at_age <-
expand.grid(
age = seq(min_age, max_age, by = time_step),
length_bin = 0:(linf_buffer * linf)
) %>%
as_data_frame() %>%
left_join(length_at_age_vars, by = 'age') %>%
arrange(age, length_bin)
p_length_at_age <- p_length_at_age %>%
group_by(age) %>%
mutate(next_length_bin = lead(length_bin, 1)) %>%
mutate(p_bin = ifelse(
is.na(next_length_bin) == F,
pnorm(next_length_bin, mean_length_at_age, sigma_at_age),1) - pnorm(length_bin, mean_length_at_age, sigma_at_age))
ggplot(p_length_at_age %>% filter(!is.na(next_length_bin)), aes(x = age, y = length_bin, fill = p_bin)) +geom_tile()
mean_length_at_age
plot(mean_length_at_age)
p_length_at_age
unique(p_length_at_age$len'')
unique(p_length_at_age$len)
unique(p_length_at_age$length_bin)
# now calculate the probability of being in each length bin at each age
p_length_at_age <-
expand.grid(
age = seq(min_age, max_age, by = time_step),
length_bin = 0:(linf_buffer * linf)
) %>%
as_data_frame() %>%
left_join(length_at_age_vars, by = 'age') %>%
arrange(age, length_bin)
p_length_at_age
linf_buffer
linf
linf_buffer = 10
mean_length_at_age <-
linf * (1 - exp(-k * (seq(
min_age, max_age, by = time_step
) - t0)))
length_at_age_vars <- data_frame(
age = seq(min_age, max_age, by = time_step),
mean_length_at_age = mean_length_at_age,
sigma_at_age = cv * mean_length_at_age
) #calculate standard deviation of length at age for each age bin
# now calculate the probability of being in each length bin at each age
p_length_at_age <-
expand.grid(
age = seq(min_age, max_age, by = time_step),
length_bin = 0:(linf_buffer * linf)
) %>%
as_data_frame() %>%
left_join(length_at_age_vars, by = 'age') %>%
arrange(age, length_bin)
p_length_at_age <- p_length_at_age %>%
group_by(age) %>%
mutate(next_length_bin = lead(length_bin, 1)) %>%
mutate(p_bin = ifelse(
is.na(next_length_bin) == F,
pnorm(next_length_bin, mean_length_at_age, sigma_at_age),1) - pnorm(length_bin, mean_length_at_age, sigma_at_age))
p_length_at_age
ggplot(p_length_at_age %>% filter(!is.na(next_length_bin)), aes(x = age, y = length_bin, fill = p_bin)) +geom_tile()
linf
linf = 50
mean_length_at_age <-
linf * (1 - exp(-k * (seq(
min_age, max_age, by = time_step
) - t0)))
length_at_age_vars <- data_frame(
age = seq(min_age, max_age, by = time_step),
mean_length_at_age = mean_length_at_age,
sigma_at_age = cv * mean_length_at_age
) #calculate standard deviation of length at age for each age bin
# now calculate the probability of being in each length bin at each age
p_length_at_age <-
expand.grid(
age = seq(min_age, max_age, by = time_step),
length_bin = 0:(linf_buffer * linf)
) %>%
as_data_frame() %>%
left_join(length_at_age_vars, by = 'age') %>%
arrange(age, length_bin)
p_length_at_age <- p_length_at_age %>%
group_by(age) %>%
mutate(next_length_bin = lead(length_bin, 1)) %>%
mutate(p_bin = ifelse(
is.na(next_length_bin) == F,
pnorm(next_length_bin, mean_length_at_age, sigma_at_age),1) - pnorm(length_bin, mean_length_at_age, sigma_at_age))
ggplot(p_length_at_age %>% filter(!is.na(next_length_bin)), aes(x = age, y = length_bin, fill = p_bin)) +geom_tile()
p_length_at_age
pnorm(5, 4, 0.5) - pnorm(4, 4, 0.5)
pnorm(5, 4, 0.5)
pnorm(4, 4, 0.5)
desperation.
# install.packages('oceanmap')
library(oceanmap)
# https://rstudio-pubs-static.s3.amazonaws.com/301644_61297506548c4b3cb9e7cc8cbc8578ce.html
# https://www.arcgis.com/home/item.html?id=24bfd85e97b042948e6ed4928dc45a8b
# devtools::install_github("yonghah/esri2sf")
library(esri2sf)
url <- "http://services1.arcgis.com/VAI453sU9tG9rSmh/arcgis/rest/services/WorldGeo_Physical_Climate_features/FeatureServer"
df <- esri2sf(url)
plot(df)
# https://data.amerigeoss.org/en_AU/dataset/major-ocean-currents-arrowpolys-30m-85
require(rgdal)
shape <- readOGR(dsn = "C:/Users/MKapur/Dropbox/UW/sab-growth/raw_data/Major_Ocean_Currents_arrowPolys_30m_8",
layer = 'Major_Ocean_Currents_arrowPolys_30m_8')
png("C:/Users/mkapur/Dropbox/mkapur.github.io/static/slides/kapur_genex/BLACK_Figure5_no130.png",
height = 10, width = 8, unit = 'in', res = 520)
lon <- c (-180, -110)
lat <- c (26, 74)
# figure ( width =9.75, height =5.28)
plotmap ( lon=lon ,  lat=lat , main ="Northeast Pacific", grid = F, col.bg = 'black', col.land = 'grey66',
cex.lab  = 2, cex.ticks = 1)
# grid()
segments(lon[1], 50, x1 = lon[2], y1 = 50, col = 'red', lty = 'dashed', lwd = 3)
segments(lon[1], 36, x1 = lon[2], y1 = 36, col = 'red', lty = 'dashed', lwd = 3)
# segments(-130, lat[1], x1 = -130, y1 = lat[2], col = 'red', lty = 'dashed', lwd = 3)
segments(-145, lat[1], x1 = -145, y1 = lat[2], col = 'blue', lty = 'dashed', lwd = 3)
rect(xleft = lon[1], ybottom = lat[1], xright = -130, ytop = 49.5, col = 'black', border = NA, add = T)
text(x = c(-155,-135,-117,-117,-115), y = c(65,65,55,45,35), size = 12, col = 'white',labels = paste('Region',5:1))
plot(shape,  ylim = lat, col = c( "gold", "dodgerblue","#ABDDA4", "#ABDDA4" ,"grey22"), border = 'white', add = T)
legend(x = -175,  bg = 'black', text.col = 'white', y = 40, legend = c('Alaskan Current','N. Pacific Current','California Current', 'S. California Bight', 'GAM-detected Regions', 'Ecosystem break'),
col = c('dodgerblue','#ABDDA4','grey22','gold','red','blue'), lty = c(rep(1,4),2,2), lwd = c(rep(5,6)))
dev.off()
## M S Kapur mod N Jacobsen Summer 2020
## kapurm@uw.edu
library(TMB)
library(dplyr)
library(reshape2)
library(ggplot2)
library(r4ss)
library(here)
library(ggsidekick)
source(here("R","functions",'load_files_OM.R'))
compile(here("TMB","runsabassessment.cpp"))
dyn.load(dynlib(here("TMB","runsabassessment")))
## OM MODEL INIT ----
# Initialize the model parameters. Make a version with movement and no seasons (simple)
df.simple <- load_data_seasons(nseason = 1,
nspace = 2,
bfuture = 0.5,
movemaxinit = 0.5,
movefiftyinit =8) # Prepare data for operating model
# Run the model using 'run.agebased.true.catch()' -- will fail if pars not == nspace
sim.data.simple <- run.agebased.true.catch(df.simple)
## sanity checks
sim.data.simple$SSB %>%
data.frame() %>%
mutate('totalSSB' = X1+X2, year = as.numeric(row.names(.))) %>%
melt(id = 'year') %>%
ggplot(., aes(x = year, y = value, color = variable)) +
geom_line(size =2 ) +  theme_sleek()
df <- load_data_seasons(nspace =2)
assessment <- read.csv(here("input","data",'assessment_MLE.csv')) ## I believe this comes from SS3
assessment <- assessment[assessment$year > 1965 &assessment$year < 2018 ,]
Catch.obs <- read.csv(here("input","data",'sab_totcatch.csv'))
df <- load_data_seasons(nspace =2)
df$Catch <- Catch.obs$Fishery
time <- 1
yrinit <- df$nyear
### Run the OM and the EM for x number of years in the MSE
### Set targets for harvesting etc
# df$parms$initN <- df$parms$initN*0
# df$parms$Rin <- df$parms$Rin*0
# df$F0 <- 0*df$F0
simyears <- 25 # Project 30 years into the future (2048 that year)
year.future <- c(df$years,(df$years[length(df$years)]+1):(df$years[length(df$years)]+simyears))
N0 <- NA
sim.data <- run.agebased.true.catch(df)
simdata0 <- sim.data # The other one is gonna get overwritten.
parms <- getParameters_OM(trueparms = TRUE, df = df)
sim.data
df
df.new <- create_TMB_data(sim.data, df, history = TRUE)
parms.new <- parms
F0 <- rowSums(sim.data$Fout)
Rdev <- parms$Rin
parms.new$F0 <- F0
parms.new$Rin <- Rdev
df.new
compile(here("TMB","runsabassessment.cpp"))
dyn.load(dynlib(here("TMB","runsabassessment")))
library(TMB)
library(dplyr)
library(reshape2)
library(ggplot2)
library(r4ss)
library(here)
library(ggsidekick)
source(here("R","functions",'load_files_OM.R'))
compile(here("TMB","runsabassessment.cpp"))
dyn.load(dynlib(here("TMB","runsabassessment")))
obj <- MakeADFun(df.new,
parms.new,
DLL= "runsabassessment") # Run the assessment, in TMB folder
reps <- obj$report()
reps$testArr
reps$N_beg
library(TMB)
library(dplyr)
library(reshape2)
library(ggplot2)
library(r4ss)
library(here)
library(ggsidekick)
source(here("R","functions",'load_files_OM.R'))
compile(here("TMB","runsabassessment.cpp"))
dyn.load(dynlib(here("TMB","runsabassessment")))
obj <- MakeADFun(df.new,
parms.new,
DLL= "runsabassessment") # Run the assessment, in TMB folder
reps <- obj$report()
reps$testArr
